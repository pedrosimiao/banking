{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tivRNaAxddBlIw4IX-qLdBVNvQKrp1fj",
      "authorship_tag": "ABX9TyP2FwzEs/qV3rxEOp3vv7bU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrosimiao/banking/blob/main/EBAC_multi_threading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import csv\n",
        "import random\n",
        "import concurrent.futures\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# global headers to be used for requests\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'}\n",
        "\n",
        "MAX_THREADS = 20\n",
        "\n",
        "\n",
        "def extract_movie_details(movie_link):\n",
        "    time.sleep(random.uniform(0, 0.3))\n",
        "    response = requests.get(movie_link, headers=headers)\n",
        "    movie_soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    if movie_soup is not None:\n",
        "        title = None\n",
        "        date = None\n",
        "\n",
        "        # Finding target section element\n",
        "        page_section = movie_soup.find('section', attrs={'class': 'ipc-page-section'})\n",
        "\n",
        "        if page_section is not None:\n",
        "            # Finding all divs in section\n",
        "            divs = page_section.find_all('div', recursive=False)\n",
        "\n",
        "            if len(divs) > 1:\n",
        "                target_div = divs[1]\n",
        "\n",
        "                # Find film title\n",
        "                title_tag = target_div.find('h1')\n",
        "                if title_tag:\n",
        "                    title = title_tag.find('span').get_text()\n",
        "\n",
        "                # Find release date\n",
        "                date_tag = target_div.find('a', href=lambda href: href and 'releaseinfo' in href)\n",
        "                if date_tag:\n",
        "                    date = date_tag.get_text().strip()\n",
        "\n",
        "                # Find ratings\n",
        "                rating_tag = movie_soup.find('div', attrs={'data-testid': 'hero-rating-bar__aggregate-rating__score'})\n",
        "                rating = rating_tag.get_text() if rating_tag else None\n",
        "\n",
        "                # Find sinopsis\n",
        "                plot_tag = movie_soup.find('span', attrs={'data-testid': 'plot-xs_to_m'})\n",
        "                plot_text = plot_tag.get_text().strip() if plot_tag else None\n",
        "\n",
        "                with open('movies.csv', mode='a', newline='', encoding='utf-8') as file:\n",
        "                    movie_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "                    if all([title, date, rating, plot_text]):\n",
        "                        print(title, date, rating, plot_text)\n",
        "                        movie_writer.writerow([title, date, rating, plot_text])\n",
        "\n",
        "\n",
        "# class = sc-5bc66c50-0 bZBaVw cli-children\n",
        "def extract_movies(soup):\n",
        "    movies_table = soup.find('div', attrs={'class': 'sc-b39631dc-3 cytPJy ipc-page-grid__item ipc-page-grid__item--span-2'}).find('ul')\n",
        "    movies_table_rows = movies_table.find_all('li')\n",
        "    movie_links = ['https://imdb.com' + movie.find('a')['href'] for movie in movies_table_rows]\n",
        "\n",
        "    threads = min(MAX_THREADS, len(movie_links))\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
        "        executor.map(extract_movie_details, movie_links)\n",
        "\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    # IMDB Most Popular Movies - 100 movies\n",
        "    popular_movies_url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
        "    response = requests.get(popular_movies_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Main function to extract the 100 movies from IMDB Most Popular Movies\n",
        "    extract_movies(soup)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print('Total time taken: ', end_time - start_time)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LscOcqVgy1e3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}